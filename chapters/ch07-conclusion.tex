% !TEX root = ../thesis.tex

\chapter{Conclusion}

In conclusion, in this work we managed to build a framework for the training and testing of various deep reinforcement learning algorithms inside of polyhedra analysis. We were then able to design a series of such algorithms. These algorithms ranged from very global reinforcement learning methods, too ones more optimised with problem specific knowledge as well as having a greater flexibility towards the various subproblems. We then tested out the different subparts of our algorithms that we had come up with, in the goal of finding an optimal combination.\\
Once our algorithms were designed, we were than able to test them on a broad array of different benchmarks. They managed to outperform the other preexisting reinforcement learning methods on both accuracy and performance.\\
It is also worth noting that we managed to highlight the overall effectiveness of the global deep Q-network algorithm, as after all it was able to craft a decision policy that was the most accurate. When designing new training algorithms that used more domain specific knowledge, we were only able to increase the performance at the loss of some accuracy.