% !TEX root = ../thesis.tex

% set counter to n-1:
\setcounter{chapter}{0}

\chapter{Introduction}
\mbox{}\\
\mbox{}\\
\mbox{}\\
%TODO make crisper email
Our ever growing reliance on computers has led to the explosion of newly written software. This growth is paralleled by the expansion of its complexity. Furthermore, an ever increasing number of the structures surrounding us has become controlled by this software. From simple things such as automatic doors to vastly more complex and important systems such as self-driving cars, medical software or nuclear weapons software. In some of these applications a program bug could simply result in a slight nuisance, but in others its existence could have major implications. The implications can be illustrated by some infamous examples where bugs such as buffer overflows, rounding errors or division by zeros have led to space craft crashes or lethal radiation overdoses. As such, due to the importance of these devices and the risk associated to potential flaws, one can see the necessity of their invulnerability and its verifiability. Unfortunately, as the complexity of these programs increases their verification can no longer be simply done by hand and the need for complete and formal verification methods becomes critical.\\
Static analysis is a sub-branch of computer science. Its task is to analyse a program without its execution. Doing so, it should discover weaknesses inside the code, weaknesses that could lead to vulnerabilities. As such, it should help with debugging and provide a better notion of safety about the code. In recent years, static analysis has seen a growing commercial use especially in safety-critical fields. Recent advances in this field use clever mathematical properties in order to increase the capabilities of such methods. Other techniques, leverage the domain of artificial intelligence to increase the fields capacities. For, until ai is capable of writing invulnerable software for us, we can at least use it to verify ours.
\section{Problem Statement}
The main focus of numerical static analysis is observing the effects that program expressions and statements have on the variables inside of the program. In order for these methods to work, a numerical abstract domain is needed that can capture the relationships between the variables. An important attribute of a domain is its expressivity, that is to say, how complex are the constraints between variables that the domain can represent. The more expressive a domain is the more complicated relationships it can represent. The most expressive domain is the polyhedra domain that represents the constraints with various polyhedra. However, its expressivity comes at a cost. It is notoriously time and space complex, having worst case exponential complexities in both. Although other domains that do not suffer from these problems also exist, they only achieve this by loosing expressivity. Various methods exist that attempt to increase the performance of the polyhedra domain. Some of these methods exchange some precision loss to increase the performance. However, finding the right balance between these two is not an easy task.

\section{Goals}
The goal of this thesis is firstly to adapt some of the recent developments in new areas of reinforcement learning in order to use them in polyhedral analysis. Secondly, we attempt to optimise said methods with some problem specific knowledge. With this we hope to increase the efficiency of the analysis and learn an action selection policy that achieves the correct balance between precision and performance, hopefully outperforming preexisting methods.

\section{Related work}
The concept of using reinforcement learning to decide between different operators with various levels of abstraction has been explored in \cite{singh2018fast}. This work used Q-learning for the Q-function approximation. Other works also explore the idea of leveraging precision loss for performance gains \cite{oh2015learning,oh2014selective,liang2011learning}. These works fall into the domain of parametric program analysis, which attempts to tune the precision and cost of the given analysis according to the program being analysed. The main difference between the above mentioned work and ours, is that they do not adaptively tune the analysis whilst it is being conducted. The work \cite{chen2008sound} uses a floating point representation of the polyhedra to increase performance with the loss of some precision as well.\\
Other works increase the performance of static analysers without the loss of precision \\ \cite{singh2015making,singh2017fast}. However these analyses remain slower than ours as with our method we were able to outperform \cite{singh2018fast}, which in turn already outperformed \cite{singh2017fast}.


\section{Structure of this Document}

\paragraph{Chapter 2}briefly introduces reinforcement learning, explaining the important concepts and its main goals. It will also describe some of the recent advances inside of the field and the achievements of these methods.

\paragraph{Chapter 3}addresses Polyhedra analysis. It will explain its usefulness inside of static analysers and how it works. The chapter also introduce some of the modifications made to the domain, in order to reduce its shortcomings.

\paragraph{Chapter 4}addresses the work done throughout this thesis. It will first address how the two previous chapters were combined and the basic algorithm was designed. The chapter also discusses the different methods tested to further optimise the results.

\paragraph{Chapter 5}discusses the different experiments that were run whilst finding the optimal combination of parts for the algorithm. The chapter also presents the results of the execution of the finalised versions of our algorithms on different benchmarks.

\paragraph{Chapter 6}will be a final conclusion on what was achieved during this thesis and the results we were able to obtain. The chapter also contains a short discussion of a few possibilities for further improvement.









